{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "IMDB_Notebook_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "42pXnMQdto-n",
        "Q1UxUZVQto-r",
        "gIuMvR9eto-6",
        "My9LyLymto_F",
        "x0XjoL72to_K",
        "69t8wNTrto_l",
        "qJOVVFFSto_o",
        "DSK4UCL7to_q",
        "RqY50Eatto_u",
        "sKqzz1BVto_2",
        "_nKpaFuuto_9"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Sw667Yto9X",
        "colab_type": "code",
        "outputId": "e48eeaff-1e03-45a5-9290-a977aebe8381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "print('GPU Name : {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n",
            "GPU Name : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNZFzaXmto9b",
        "colab_type": "text"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
        " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
        " #### [3. The Embedding layer](#coding_tutorial_3)\n",
        " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
        " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
        " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUfr2CDNto9c",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhl69fK0to9c",
        "colab_type": "text"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF73lW5Nto9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import imdb\n",
        "\n",
        "import tensorflow.keras.datasets.imdb as imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDt4bDw9to9g",
        "colab_type": "code",
        "outputId": "cc565020-9d2e-4f2d-d8f2-3e19eb809577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# imdb data object has two methods only load_data and get_word_index.\n",
        "# Download and assign the data set using load_data()\n",
        "# This command downloads the IMDb dataset from the tensorflow servers, saves it to your hard drive, and loads it into Python as numpy rows.\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq6RsXqcto9i",
        "colab_type": "text"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuSeJAblto9j",
        "colab_type": "code",
        "outputId": "752230f4-a999-41ff-b2f0-a24084d4d255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Inspect the type of the data\n",
        "\n",
        "type(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pLPifrsto9l",
        "colab_type": "code",
        "outputId": "f57c8db7-a9f7-4e85-c2cd-cfa465296f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Inspect the shape of the data\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqrdS2bsto9p",
        "colab_type": "code",
        "outputId": "ce2c5721-2d6a-4445-e062-75df4bab5110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "\n",
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyzx2ABsto9s",
        "colab_type": "code",
        "outputId": "0824eca2-acb2-4e01-e0b2-6107e87ac36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Display the first dataset element output\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZoSoR4-to9u",
        "colab_type": "text"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51mvEPvato9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset with defaults\n",
        "# The way the encoding works is that each word in the vocabulary is mapped to an integer representing its frequency rank.\n",
        "# This rank is then adjusted by adding the index from value to it. \n",
        "# This mapping from vocabulary words to adjusted frequency ranks is called the dataset's word index.\n",
        "imdb.load_data(path='imdb.npz', index_from=3)\n",
        "\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8spK8Fg_to9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "# if you wanted to include words of an adjusted frequency rank of less than 1,000, you would write num_words=1000.\n",
        "# you might remove those 10 from a word index with a maximum adjusted frequency rank of 1000.\n",
        "\n",
        "imdb.load_data(num_words=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtcCaJljto9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "# If you wanted to remove the ten most frequent words, you would write skip_top=10, if you feel they are not valuable.\n",
        "# Words that aren't in the word index are mapped to the value of the OOVI char argument of load data. By default, its 2\n",
        "\n",
        "\n",
        "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-khazB9Tto91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "# You can also set the maximum review length using the max line argument. \n",
        "\n",
        "imdb.load_data(maxlen=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv-aWdAwto94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use '1' as the character that indicates the start of a sequence\n",
        "# You can also configure the number that indicates the start of a sequence via start char.\n",
        "# his character will appear at the beginning of every sequence in the downloaded dataset. By default it is equal to 1.\n",
        "\n",
        "imdb.load_data(start_char=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec05Q5Qbto96",
        "colab_type": "text"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyICcIbCto96",
        "colab_type": "code",
        "outputId": "ee3ac81a-7e0e-4674-f7a2-43bc417370bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "# This method downloads the complete frequency ranking of words in the whole IMDb data et. \n",
        "\n",
        "imdb_word_index = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGO6blESto99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "# To use the word index to decode reviews, you need to adjust the indices by the index from value in load data. By default, this is equal to 3.\n",
        "# To make the adjustment, simply overwrite the existing word index with a dictionary with the same keys and the values adjusted by the index from value.\n",
        "\n",
        "index_from = 3\n",
        "imdb_word_index = {key:value + index_from for key, value in imdb_word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg12T_Bjto9_",
        "colab_type": "code",
        "outputId": "f0488281-77c4-4ec7-ce8f-bc211b206660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "imdb_word_index['simpsonian']\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb3LWDDgWXo6",
        "colab_type": "code",
        "outputId": "fd2b274a-7b42-4b5f-835d-4a21a0cfdfce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "imdb_word_index['the']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBKte_rjto-B",
        "colab_type": "code",
        "outputId": "a7c98a01-c52a-451a-dda9-21f6df480627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# View an input sentence\n",
        "# Now on to decoding a review. Since the Python dictionary is indexed by its keys, we need to swap the keys and values of the word index object.\n",
        "\n",
        "inv_imdb_word_index = {value:key for key, value in imdb_word_index.items()}\n",
        "\n",
        "# You can then decode a review by passing a sequence of indices to the inverted word index. \n",
        "# The last condition is necessary since the word index does not know of the sequence start value nor the out of vocabulary value.\n",
        "\n",
        "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'film',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'casting',\n",
              " 'location',\n",
              " 'scenery',\n",
              " 'story',\n",
              " 'direction',\n",
              " \"everyone's\",\n",
              " 'really',\n",
              " 'suited',\n",
              " 'the',\n",
              " 'part',\n",
              " 'they',\n",
              " 'played',\n",
              " 'and',\n",
              " 'you',\n",
              " 'could',\n",
              " 'just',\n",
              " 'imagine',\n",
              " 'being',\n",
              " 'there',\n",
              " 'robert',\n",
              " \"redford's\",\n",
              " 'is',\n",
              " 'an',\n",
              " 'amazing',\n",
              " 'actor',\n",
              " 'and',\n",
              " 'now',\n",
              " 'the',\n",
              " 'same',\n",
              " 'being',\n",
              " 'director',\n",
              " \"norman's\",\n",
              " 'father',\n",
              " 'came',\n",
              " 'from',\n",
              " 'the',\n",
              " 'same',\n",
              " 'scottish',\n",
              " 'island',\n",
              " 'as',\n",
              " 'myself',\n",
              " 'so',\n",
              " 'i',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'real',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'this',\n",
              " 'film',\n",
              " 'the',\n",
              " 'witty',\n",
              " 'remarks',\n",
              " 'throughout',\n",
              " 'the',\n",
              " 'film',\n",
              " 'were',\n",
              " 'great',\n",
              " 'it',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'so',\n",
              " 'much',\n",
              " 'that',\n",
              " 'i',\n",
              " 'bought',\n",
              " 'the',\n",
              " 'film',\n",
              " 'as',\n",
              " 'soon',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'released',\n",
              " 'for',\n",
              " 'retail',\n",
              " 'and',\n",
              " 'would',\n",
              " 'recommend',\n",
              " 'it',\n",
              " 'to',\n",
              " 'everyone',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'and',\n",
              " 'the',\n",
              " 'fly',\n",
              " 'fishing',\n",
              " 'was',\n",
              " 'amazing',\n",
              " 'really',\n",
              " 'cried',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " 'it',\n",
              " 'was',\n",
              " 'so',\n",
              " 'sad',\n",
              " 'and',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " 'they',\n",
              " 'say',\n",
              " 'if',\n",
              " 'you',\n",
              " 'cry',\n",
              " 'at',\n",
              " 'a',\n",
              " 'film',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'been',\n",
              " 'good',\n",
              " 'and',\n",
              " 'this',\n",
              " 'definitely',\n",
              " 'was',\n",
              " 'also',\n",
              " 'congratulations',\n",
              " 'to',\n",
              " 'the',\n",
              " 'two',\n",
              " 'little',\n",
              " \"boy's\",\n",
              " 'that',\n",
              " 'played',\n",
              " 'the',\n",
              " \"part's\",\n",
              " 'of',\n",
              " 'norman',\n",
              " 'and',\n",
              " 'paul',\n",
              " 'they',\n",
              " 'were',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'children',\n",
              " 'are',\n",
              " 'often',\n",
              " 'left',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'praising',\n",
              " 'list',\n",
              " 'i',\n",
              " 'think',\n",
              " 'because',\n",
              " 'the',\n",
              " 'stars',\n",
              " 'that',\n",
              " 'play',\n",
              " 'them',\n",
              " 'all',\n",
              " 'grown',\n",
              " 'up',\n",
              " 'are',\n",
              " 'such',\n",
              " 'a',\n",
              " 'big',\n",
              " 'profile',\n",
              " 'for',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'film',\n",
              " 'but',\n",
              " 'these',\n",
              " 'children',\n",
              " 'are',\n",
              " 'amazing',\n",
              " 'and',\n",
              " 'should',\n",
              " 'be',\n",
              " 'praised',\n",
              " 'for',\n",
              " 'what',\n",
              " 'they',\n",
              " 'have',\n",
              " 'done',\n",
              " \"don't\",\n",
              " 'you',\n",
              " 'think',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'story',\n",
              " 'was',\n",
              " 'so',\n",
              " 'lovely',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'true',\n",
              " 'and',\n",
              " 'was',\n",
              " \"someone's\",\n",
              " 'life',\n",
              " 'after',\n",
              " 'all',\n",
              " 'that',\n",
              " 'was',\n",
              " 'shared',\n",
              " 'with',\n",
              " 'us',\n",
              " 'all']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9EURPAqto-E",
        "colab_type": "code",
        "outputId": "478f08ab-d0d3-473a-f51f-93391b1a826c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the sentiment value\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCimBCwZto-G",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb1KXXrGto-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the imdb data set\n",
        "import tensorflow.keras.datasets.imdb as imdb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edIIYUE4to-I",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RByOZnw9to-J",
        "colab_type": "code",
        "outputId": "e8e080d5-fb10-4a50-c330-2f98ffba6dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Inspect the input data shape\n",
        "# Its ragged ndarray\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5ZYrSo7to-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen\n",
        "\n",
        "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding='post', truncating='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHKhxG92to-M",
        "colab_type": "code",
        "outputId": "71b299ff-22f3-4aee-e15d-9ef109649e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Inspect the output data shape\n",
        "# Now its proper rectangular array with 300 columns.\n",
        "# The default padding value for pad sequences is 0\n",
        "# Padding values are non-informative about our sequences contents. \n",
        "# To allow recurrent units to identify and skip padding values you can include a masking layer in your model.\n",
        "\n",
        "padded_x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpjuzqItto-O",
        "colab_type": "text"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHr7GZ6Lto-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import numpy \n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VYg6BMkto-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "# if we're currently sees that all values at a time step across a batch are masked, the layer will skip that time step.\n",
        "\n",
        "padded_x_train = np.expand_dims(padded_x_train, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otgfMcP7to-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Masking layer \n",
        "\n",
        "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
        "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qnifGsmto-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "\n",
        "masked_x_train = masking_layer(tf_x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPJmNo3Hto-Y",
        "colab_type": "code",
        "outputId": "044171c1-b82a-4cba-abc6-1d4ed9dcb51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "# Look at the dataset\n",
        "\n",
        "tf_x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300, 1), dtype=float32, numpy=\n",
              "array([[[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [2.200e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.940e+02],\n",
              "        [1.153e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [4.700e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.100e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.446e+03],\n",
              "        [7.079e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.700e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN6cCBXmdMiI",
        "colab_type": "code",
        "outputId": "a3d203ed-2fe6-458b-a1fd-b3786616e5f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "masked_x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300, 1), dtype=float32, numpy=\n",
              "array([[[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [2.200e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.940e+02],\n",
              "        [1.153e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [4.700e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.100e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.446e+03],\n",
              "        [7.079e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.700e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9S0LFBto-a",
        "colab_type": "code",
        "outputId": "bcc6b379-2d0c-4cee-b37e-cab403b149ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "\n",
        "tf_x_train._keras_mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-23b46631e2fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf_x_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LCeV1w6de6w",
        "colab_type": "code",
        "outputId": "ffabdf3a-9efe-474a-cae7-117d07111906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# in this tensor, true locate real sequence values, whereas false locates padding values.\n",
        "# It's this property keras mask that recurrent layers refer to when deciding whether or not to skip a time step in a batch.\n",
        "\n",
        "masked_x_train._keras_mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGy3aPJWto-e",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d5Bq1hLto-e",
        "colab_type": "text"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xPxckIPto-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim, output_dim, input_length\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0-3dtjHto-h",
        "colab_type": "code",
        "outputId": "520a364d-3636-41b4-9623-b6e53587d361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "# Passing a single sequence of indices to our embedding layer so we can see how each entry in the sequence is being mapped to it's embedding.\n",
        "# Create the sequence, sequence of indices using tf.constant,\n",
        "# and create a batch containing a single sequence with each feature vector in the sequence containing a single value, with the values being 0, 1, 5, and 500. \n",
        "# Notice that I've created a feature dimension in spite of the fact that the sequence only contains a single value at each time step. \n",
        "# This is because the embedding layer expected inputs of shape, batch sequence features. \n",
        "# Pass the sequence of indices to embedding layer and save the output to sequence of embeddings.\n",
        "# You can see from the output that the sequence length has remained the same while the indices have been replaced by their embeddings, each of which is a 16-dimensional vector\n",
        "\n",
        "sequence_of_indices = tf.constant([[[0],[1],[5],[500]]])\n",
        "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
        "sequence_of_embeddings"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
              "array([[[[ 0.04872428,  0.04241559, -0.02356823, -0.0453388 ,\n",
              "          -0.00788896,  0.01631159, -0.00510161,  0.02773961,\n",
              "           0.03793502,  0.02912446, -0.02531645, -0.01535088,\n",
              "           0.03700543, -0.02077115, -0.03227865,  0.00406898]],\n",
              "\n",
              "        [[-0.01552264, -0.03632841, -0.02872068,  0.03257276,\n",
              "          -0.04046204,  0.03059119, -0.01759539,  0.01969856,\n",
              "           0.0214942 ,  0.03030428,  0.0393054 ,  0.03906641,\n",
              "           0.00290219,  0.03962889, -0.01857651, -0.00889333]],\n",
              "\n",
              "        [[-0.04934983, -0.03918725, -0.00555604, -0.02095532,\n",
              "           0.01045794,  0.02950301,  0.01630105,  0.03874901,\n",
              "          -0.04243469,  0.00859357,  0.00643158,  0.02742912,\n",
              "          -0.04584656,  0.02673521,  0.01374116,  0.02838203]],\n",
              "\n",
              "        [[-0.04761389, -0.01296924, -0.04377239, -0.03798524,\n",
              "           0.0114585 ,  0.02688969, -0.0088779 ,  0.03528554,\n",
              "           0.0262918 , -0.02446668,  0.01561806,  0.04382229,\n",
              "          -0.04668557, -0.02495903,  0.0016716 , -0.02700118]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWWuRsNqLC0j",
        "colab_type": "code",
        "outputId": "271706a4-298f-4ef4-b440-330fc437ea73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "import numpy as np \n",
        "embedding_layer = Embedding(1000,32,input_length = 64, mask_zero=True)\n",
        "test_input = np.random.randint(1000, size=(16,64))\n",
        "embedded_inputs = embedding_layer(test_input)\n",
        "print(embedded_inputs)\n",
        "embedded_inputs._keras_mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[-4.72978614e-02 -2.99745798e-02 -3.39182615e-02 ...  3.12484838e-02\n",
            "    7.69959763e-03 -3.59261036e-02]\n",
            "  [-4.44185995e-02 -1.05785243e-02  3.54325771e-03 ...  3.83838154e-02\n",
            "   -4.54059988e-03 -3.88224125e-02]\n",
            "  [ 2.57592537e-02 -4.53229658e-02  4.60560434e-02 ...  2.57410668e-02\n",
            "    3.13606113e-03 -9.74640995e-03]\n",
            "  ...\n",
            "  [-2.76311524e-02  3.59730795e-03 -1.31364465e-02 ... -4.96701114e-02\n",
            "    4.82204817e-02 -9.82445478e-03]\n",
            "  [-2.92846803e-02  3.10540199e-05 -1.19088665e-02 ... -2.26016045e-02\n",
            "    3.63291390e-02  4.24697883e-02]\n",
            "  [ 4.42635678e-02 -3.13893445e-02  1.89867057e-02 ... -3.41523066e-02\n",
            "    5.06749004e-03  2.06539147e-02]]\n",
            "\n",
            " [[-1.91206466e-02  2.92468704e-02 -1.80845633e-02 ... -4.13577780e-02\n",
            "    1.68047659e-02  8.53818655e-03]\n",
            "  [-1.91637874e-02  1.22662894e-02  4.34458256e-03 ... -3.70009765e-02\n",
            "   -4.64978330e-02 -4.62268367e-02]\n",
            "  [-7.08645582e-03 -4.12947908e-02  3.81530263e-02 ...  4.87723984e-02\n",
            "   -2.18096375e-02 -4.24111485e-02]\n",
            "  ...\n",
            "  [ 4.51833718e-02  3.98181416e-02  3.79689373e-02 ... -4.21617627e-02\n",
            "   -1.89113375e-02 -3.71515378e-02]\n",
            "  [ 1.03805661e-02 -1.42727382e-02  9.51043516e-03 ...  2.54139788e-02\n",
            "   -1.08942166e-02  1.62788369e-02]\n",
            "  [-2.76311524e-02  3.59730795e-03 -1.31364465e-02 ... -4.96701114e-02\n",
            "    4.82204817e-02 -9.82445478e-03]]\n",
            "\n",
            " [[-2.10400224e-02 -2.10035332e-02  2.72837169e-02 ...  4.95420955e-02\n",
            "    4.72367294e-02 -8.41035694e-03]\n",
            "  [ 2.32352130e-02 -3.35756168e-02 -2.63022073e-02 ... -2.51372810e-02\n",
            "    1.92006491e-02  4.52671312e-02]\n",
            "  [ 3.53492238e-02 -3.33074480e-03 -3.54655758e-02 ...  1.75095238e-02\n",
            "    3.95017155e-02  3.74499708e-03]\n",
            "  ...\n",
            "  [-9.89533588e-03  3.99518497e-02 -3.18014845e-02 ...  3.69244926e-02\n",
            "    3.65674496e-03 -8.91529024e-04]\n",
            "  [ 2.02394240e-02  2.81502716e-02 -4.41106446e-02 ...  4.53391187e-02\n",
            "    1.12040415e-02  7.64243677e-03]\n",
            "  [-3.22931036e-02 -3.67341638e-02  3.24221700e-03 ... -2.65963320e-02\n",
            "    4.37647142e-02 -3.06034088e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-4.79763411e-02 -9.91523266e-03  1.83846802e-03 ... -4.26256657e-03\n",
            "    4.75498550e-02 -2.04121470e-02]\n",
            "  [ 7.72801787e-03 -3.70552540e-02  1.09492764e-02 ...  4.90588285e-02\n",
            "   -2.36529596e-02  1.33205764e-02]\n",
            "  [-2.10400224e-02 -2.10035332e-02  2.72837169e-02 ...  4.95420955e-02\n",
            "    4.72367294e-02 -8.41035694e-03]\n",
            "  ...\n",
            "  [-1.27810724e-02  4.15940322e-02 -1.65755861e-02 ...  9.34408978e-03\n",
            "   -1.85561664e-02  2.50051655e-02]\n",
            "  [-3.00605223e-03 -4.31855805e-02  3.65207307e-02 ...  2.69952081e-02\n",
            "   -1.37051567e-02  3.96076106e-02]\n",
            "  [-2.23820936e-02  2.89413072e-02  2.90773846e-02 ... -1.42718665e-02\n",
            "   -1.16063729e-02  1.96185745e-02]]\n",
            "\n",
            " [[-2.38605142e-02  1.67206265e-02  3.96882370e-03 ...  3.39583047e-02\n",
            "    1.54618360e-02 -9.41538811e-03]\n",
            "  [-1.33137815e-02 -3.42888385e-02  3.46394442e-02 ... -1.84427388e-02\n",
            "    3.67391221e-02 -3.35928425e-02]\n",
            "  [ 2.42522694e-02 -4.73015681e-02  4.81576845e-03 ... -4.43391874e-03\n",
            "    1.16433948e-03  4.52106073e-03]\n",
            "  ...\n",
            "  [-1.83279514e-02  1.17639527e-02 -1.88503750e-02 ...  1.47894733e-02\n",
            "   -3.11130174e-02 -1.44647732e-02]\n",
            "  [ 3.24903019e-02 -3.15003619e-02  4.89182398e-03 ...  2.25495733e-02\n",
            "    4.07901146e-02  1.30537637e-02]\n",
            "  [-4.86960076e-02 -4.45550457e-02  4.09733541e-02 ... -2.87552010e-02\n",
            "   -2.02954412e-02 -4.48753349e-02]]\n",
            "\n",
            " [[ 3.43340375e-02  4.13876809e-02  2.48316675e-03 ...  3.00064571e-02\n",
            "   -2.86216494e-02 -1.95835587e-02]\n",
            "  [ 3.80403921e-03 -5.62108681e-03 -2.13812590e-02 ...  1.08916648e-02\n",
            "   -5.11870533e-03 -2.15011835e-02]\n",
            "  [ 4.90405075e-02 -3.06239966e-02  1.62693001e-02 ...  2.22655050e-02\n",
            "    4.43375744e-02 -1.26140714e-02]\n",
            "  ...\n",
            "  [ 1.32686608e-02 -1.36054382e-02  1.27193369e-02 ...  3.62884067e-02\n",
            "   -3.29959169e-02 -2.07893383e-02]\n",
            "  [-4.65686247e-03  9.49501991e-04  3.35523598e-02 ... -3.94478329e-02\n",
            "    4.88394015e-02 -3.53427753e-02]\n",
            "  [-4.44220416e-02  2.81542204e-02 -8.34826380e-03 ... -4.36642170e-02\n",
            "   -2.52067093e-02  1.99075788e-03]]], shape=(16, 64, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 64), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO1y88zxto-i",
        "colab_type": "code",
        "outputId": "fb230fe6-c03d-454f-e887-7b658a6acfd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "\n",
        "embedding_layer.get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04872428,  0.04241559, -0.02356823, ..., -0.02077115,\n",
              "        -0.03227865,  0.00406898],\n",
              "       [-0.01552264, -0.03632841, -0.02872068, ...,  0.03962889,\n",
              "        -0.01857651, -0.00889333],\n",
              "       [ 0.01166313,  0.01567569, -0.01127052, ..., -0.02864438,\n",
              "        -0.01276373, -0.00039077],\n",
              "       ...,\n",
              "       [-0.02727896, -0.01856013,  0.04692454, ..., -0.04542042,\n",
              "        -0.01443933, -0.00460063],\n",
              "       [-0.04997784,  0.0203336 , -0.00642265, ...,  0.03978759,\n",
              "         0.02117715, -0.04200948],\n",
              "       [-0.04761389, -0.01296924, -0.04377239, ..., -0.02495903,\n",
              "         0.0016716 , -0.02700118]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shmodfltto-l",
        "colab_type": "code",
        "outputId": "49b64ae2-e0db-4c96-87a9-8397a231a242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Get the embedding for the 14th index\n",
        "\n",
        "embedding_layer.get_weights()[0][14,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0451032 , -0.03019304, -0.00404735, -0.02187367, -0.03189258,\n",
              "        0.04667951, -0.04117098,  0.04562496, -0.00720056, -0.0432821 ,\n",
              "       -0.04140819, -0.0249688 ,  0.01154352, -0.00842356,  0.00499067,\n",
              "       -0.03307437], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42pXnMQdto-n",
        "colab_type": "text"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_ve_k6Wto-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "\n",
        "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16, mask_zero=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XigSbZGtto-p",
        "colab_type": "code",
        "outputId": "b6dc395b-ea66-4512-f4de-869e5b50cdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "\n",
        "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
        "masked_sequence_of_embeddings._keras_mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1), dtype=bool, numpy=\n",
              "array([[[False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deAkaJWuto-r",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1UxUZVQto-r",
        "colab_type": "text"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrBZ9jN1to-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjsJgOh8to-u",
        "colab_type": "code",
        "outputId": "f3317fb0-566c-4005-c28a-19d439f543cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-229Our49lkx",
        "colab_type": "code",
        "outputId": "7a9f07cc-db24-4484-e5b1-53075666d222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2494)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_wnAfinto-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF_Nq1NAto-z",
        "colab_type": "code",
        "outputId": "cbbb53c7-2cf5-4363-b3dc-77bcf401d9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Get the word index\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9DHnBRkto-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "\n",
        "inv_imdb_word_index = {value : key for key, value in imdb_word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1UgSSDmto-3",
        "colab_type": "code",
        "outputId": "4d9b8fec-2c1c-4b02-919c-b38def120522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# View the first dataset example sentence\n",
        "\n",
        "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'a',\n",
              " 'great',\n",
              " 'fan',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'and',\n",
              " 'have',\n",
              " 'everything',\n",
              " 'that',\n",
              " \"he's\",\n",
              " 'made',\n",
              " 'on',\n",
              " 'dvd',\n",
              " 'except',\n",
              " 'for',\n",
              " 'hotel',\n",
              " 'room',\n",
              " 'the',\n",
              " '2',\n",
              " 'hour',\n",
              " 'twin',\n",
              " 'peaks',\n",
              " 'movie',\n",
              " 'so',\n",
              " 'when',\n",
              " 'i',\n",
              " 'found',\n",
              " 'out',\n",
              " 'about',\n",
              " 'this',\n",
              " 'i',\n",
              " 'immediately',\n",
              " 'grabbed',\n",
              " 'it',\n",
              " 'and',\n",
              " 'and',\n",
              " 'what',\n",
              " 'is',\n",
              " 'this',\n",
              " \"it's\",\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'drawn',\n",
              " 'black',\n",
              " 'and',\n",
              " 'white',\n",
              " 'cartoons',\n",
              " 'that',\n",
              " 'are',\n",
              " 'loud',\n",
              " 'and',\n",
              " 'foul',\n",
              " 'mouthed',\n",
              " 'and',\n",
              " 'unfunny',\n",
              " 'maybe',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " \"what's\",\n",
              " 'good',\n",
              " 'but',\n",
              " 'maybe',\n",
              " 'this',\n",
              " 'is',\n",
              " 'just',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'crap',\n",
              " 'that',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'public',\n",
              " 'under',\n",
              " 'the',\n",
              " 'name',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'to',\n",
              " 'make',\n",
              " 'a',\n",
              " 'few',\n",
              " 'bucks',\n",
              " 'too',\n",
              " 'let',\n",
              " 'me',\n",
              " 'make',\n",
              " 'it',\n",
              " 'clear',\n",
              " 'that',\n",
              " 'i',\n",
              " \"didn't\",\n",
              " 'care',\n",
              " 'about',\n",
              " 'the',\n",
              " 'foul',\n",
              " 'language',\n",
              " 'part',\n",
              " 'but',\n",
              " 'had',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'because',\n",
              " 'my',\n",
              " 'neighbors',\n",
              " 'might',\n",
              " 'have',\n",
              " 'all',\n",
              " 'in',\n",
              " 'all',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'highly',\n",
              " 'disappointing',\n",
              " 'release',\n",
              " 'and',\n",
              " 'may',\n",
              " 'well',\n",
              " 'have',\n",
              " 'just',\n",
              " 'been',\n",
              " 'left',\n",
              " 'in',\n",
              " 'the',\n",
              " 'box',\n",
              " 'set',\n",
              " 'as',\n",
              " 'a',\n",
              " 'curiosity',\n",
              " 'i',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'you',\n",
              " \"don't\",\n",
              " 'spend',\n",
              " 'your',\n",
              " 'money',\n",
              " 'on',\n",
              " 'this',\n",
              " '2',\n",
              " 'out',\n",
              " 'of',\n",
              " '10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIuMvR9eto-6",
        "colab_type": "text"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js1Jf7E0to-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the maximum token value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz0gnd7-to-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify an embedding dimension\n",
        "\n",
        "embedding_dim = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAwF8PQ-to--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=max_index_value + 1, output_dim = embedding_dim, mask_zero=False),\n",
        "                                    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                                    tf.keras.layers.Dense(units = 1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ0MZj2nto_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "\n",
        "review_sequence = tf.keras.Input((None,))\n",
        "embedding_sequence = tf.keras.layers.Embedding(input_dim=max_index_value + 1, output_dim=embedding_dim)(review_sequence)\n",
        "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
        "positive_probability = tf.keras.layers.Dense(units = 1, activation = 'sigmoid')(average_embedding)\n",
        "\n",
        "model = tf.keras.Model(inputs = review_sequence, outputs = positive_probability)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsv6wwdvto_D",
        "colab_type": "code",
        "outputId": "ac560815-7878-4840-d13b-a37287bbdf6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My9LyLymto_F",
        "colab_type": "text"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ha3f3hVto_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxuuaVuFto_H",
        "colab_type": "code",
        "outputId": "89f36a3b-1be2-4838-ceea-7ae2ccfa0392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6898 - accuracy: 0.5487 - val_loss: 0.6836 - val_accuracy: 0.7391\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6709 - accuracy: 0.6853 - val_loss: 0.6506 - val_accuracy: 0.7125\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6291 - accuracy: 0.7494 - val_loss: 0.6026 - val_accuracy: 0.7641\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5786 - accuracy: 0.7895 - val_loss: 0.5547 - val_accuracy: 0.7859\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5299 - accuracy: 0.8141 - val_loss: 0.5142 - val_accuracy: 0.7906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7WK8x4uto_J",
        "colab_type": "code",
        "outputId": "a1332ac2-7880-46ad-a3d7-1d73ddf46eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0XjoL72to_K",
        "colab_type": "text"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlun4pkmto_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "\n",
        "weights = model.layers[1].get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53a1CwThto_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "out_v = io.open('/content/drive/My Drive/Colab Notebooks/vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('/content/drive/My Drive/Colab Notebooks/meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in imdb_word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRFs2Kc_w1q",
        "colab_type": "code",
        "outputId": "18d1e66b-ca43-494d-d39c-9e582aabd77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_UKoDlzto_P",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_1sBs-9to_Q",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD5Ikxb_to_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "# By default, RNN layers only return the final output, not the entire sequence of outputs. \n",
        "# To see this, pass the batch containing a single sequence of two-dimensional vectors to the latter\n",
        "\n",
        "\n",
        "simplernn_layer = tf.keras.layers.SimpleRNN(units=16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dpayKmwto_U",
        "colab_type": "code",
        "outputId": "5ed9d997-a560-4d64-9cc1-7c9f57834a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "# You can see that this layers output is a single vector of length 16. This is because their current layer contains 16 units.\n",
        "# The sequence two-dimensional vectors has been mapped to a single 16 dimensional vector\n",
        "\n",
        "sequence = tf.constant([[[1. , 1.], [2., 2.], [56. , -100.]]])\n",
        "layer_output = simplernn_layer(sequence)\n",
        "layer_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[-1.        , -1.        , -0.9909561 ,  1.        ,  1.        ,\n",
              "        -1.        , -1.        , -0.99822575,  0.99959105, -1.        ,\n",
              "         1.        ,  1.        , -0.97956085,  1.        , -1.        ,\n",
              "        -1.        ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUwniWjVto_W",
        "colab_type": "text"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh9AAykKto_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbAgaN6mto_a",
        "colab_type": "code",
        "outputId": "10473207-6278-4ef5-bafc-0210cc710f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI7BXFX_to_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPTUbWhNto_d",
        "colab_type": "code",
        "outputId": "feb5acf3-2260-49a1-9c77-b865c93d3907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dEqQWt9to_g",
        "colab_type": "text"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITtIvfb-to_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the maximum index value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "embedding_dim = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wGCp5xuto_k",
        "colab_type": "code",
        "outputId": "fd44c634-d16e-4e26-9934-708dbdaed3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=max_index_value + 1, output_dim = embedding_dim, mask_zero=True),\n",
        "                                    tf.keras.layers.LSTM(units=16),\n",
        "                                    tf.keras.layers.Dense(units = 1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 162,145\n",
            "Trainable params: 162,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69t8wNTrto_l",
        "colab_type": "text"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpKdzQN6to_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QevSWuPnto_n",
        "colab_type": "code",
        "outputId": "bdb412ba-2453-4e1c-8fd3-e275cc6aad39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# Fit the model and save its training history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 411s 525ms/step - loss: 0.4098 - accuracy: 0.8085\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 410s 524ms/step - loss: 0.2268 - accuracy: 0.9133\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 411s 525ms/step - loss: 0.1761 - accuracy: 0.9368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJOVVFFSto_o",
        "colab_type": "text"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur9nzRBPto_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSK4UCL7to_q",
        "colab_type": "text"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynfiQbZUto_q",
        "colab_type": "code",
        "outputId": "7b3d1897-7e85-421f-baf1-04da86372f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "\n",
        "inv_imdb_word_index = {value:key for key,value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_test[0] if index > 2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ignore',\n",
              " 'the',\n",
              " 'bad',\n",
              " 'reviews',\n",
              " 'on',\n",
              " 'here',\n",
              " 'this',\n",
              " 'film',\n",
              " 'is',\n",
              " 'awesome',\n",
              " 'just',\n",
              " 'before',\n",
              " 'dawn',\n",
              " 'is',\n",
              " 'a',\n",
              " 'great',\n",
              " 'example',\n",
              " 'of',\n",
              " 'what',\n",
              " 'can',\n",
              " 'be',\n",
              " 'done',\n",
              " 'in',\n",
              " 'a',\n",
              " 'film',\n",
              " 'with',\n",
              " 'a',\n",
              " 'minimal',\n",
              " 'budget',\n",
              " 'if',\n",
              " 'you',\n",
              " 'have',\n",
              " 'a',\n",
              " 'dedicated',\n",
              " 'crew',\n",
              " 'decent',\n",
              " 'script',\n",
              " 'and',\n",
              " 'a',\n",
              " 'cool',\n",
              " 'idea',\n",
              " 'for',\n",
              " 'a',\n",
              " 'film',\n",
              " \"it's\",\n",
              " 'a',\n",
              " 'hell',\n",
              " 'of',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'fun',\n",
              " 'br',\n",
              " 'br',\n",
              " 'i',\n",
              " 'enjoyed',\n",
              " 'it',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'more',\n",
              " 'than',\n",
              " 'most',\n",
              " 'other',\n",
              " \"80's\",\n",
              " 'slashers',\n",
              " 'because',\n",
              " 'the',\n",
              " 'killer',\n",
              " 'is',\n",
              " 'so',\n",
              " 'unique',\n",
              " 'wrong',\n",
              " 'turn',\n",
              " 'ripped',\n",
              " 'this',\n",
              " 'movie',\n",
              " 'off',\n",
              " 'something',\n",
              " 'fierce',\n",
              " \"there's\",\n",
              " 'plenty',\n",
              " 'of',\n",
              " 'blood',\n",
              " 'and',\n",
              " 'scares',\n",
              " 'my',\n",
              " 'girlfriend',\n",
              " 'was',\n",
              " 'freaked',\n",
              " 'out',\n",
              " 'and',\n",
              " 'she',\n",
              " 'watches',\n",
              " 'almost',\n",
              " 'everything',\n",
              " 'with',\n",
              " 'me',\n",
              " 'and',\n",
              " \"doesn't\",\n",
              " \"it's\",\n",
              " 'got',\n",
              " 'that',\n",
              " 'creepiness',\n",
              " 'to',\n",
              " 'it',\n",
              " 'br',\n",
              " 'br',\n",
              " \"i'd\",\n",
              " 'say',\n",
              " 'that',\n",
              " 'just',\n",
              " 'before',\n",
              " 'dawn',\n",
              " 'is',\n",
              " 'the',\n",
              " 'best',\n",
              " 'early',\n",
              " \"80's\",\n",
              " 'slasher',\n",
              " 'out',\n",
              " 'there',\n",
              " 'i',\n",
              " 'really',\n",
              " 'enjoyed',\n",
              " 'it',\n",
              " 'br',\n",
              " 'br',\n",
              " '8',\n",
              " 'out',\n",
              " 'of',\n",
              " '10',\n",
              " 'kids']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtbbUlL5to_r",
        "colab_type": "code",
        "outputId": "2d6eb6ae-4bc9-436f-c859-f3f6bab21607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "\n",
        "model.predict(x_test[None,0,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9945374]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJCzlexSto_t",
        "colab_type": "code",
        "outputId": "28589089-2384-4cc4-c5a8-71ca399ade42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the corresponding label\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPcciqntto_u",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqY50Eatto_u",
        "colab_type": "text"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SaWgA9rto_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL5jq2HOto_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "359839ac-f71d-40f7-8eeb-57841fa8f688"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words=5000, maxlen=250)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuX3QBQIto_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrD0g9JOto_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a4ba84a1-d3f7-4ed4-ba77-aa9e1194d4da"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "imdb_word_index = get_imdb_word_index(num_words=5000)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKqzz1BVto_2",
        "colab_type": "text"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95hJWhzbto_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "embedding_dim = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd7YzFbmto_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
        "                             tf.keras.layers.LSTM(units=32, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(units=32, return_sequences=False),\n",
        "                             tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVNotfIRto_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
        "                             tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8), merge_mode='sum', \n",
        "                                                           backward_layer=tf.keras.layers.GRU(units=8, go_backwards=True)),\n",
        "                             tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9n2m_mtto_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
        "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=8, return_sequences=True), merge_mode='concat'),\n",
        "                             tf.keras.layers.GRU(units = 8, return_sequences=False),\n",
        "                             tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nKpaFuuto_9",
        "colab_type": "text"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Md0xOqto_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcbgwKJXto_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "10779e01-fb78-4f08-ce20-aa5f4ff84b12"
      },
      "source": [
        "# Train the model, saving its history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 1720s 2s/step - loss: 0.3773 - accuracy: 0.8277\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 1731s 2s/step - loss: 0.2364 - accuracy: 0.9096\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 1711s 2s/step - loss: 0.1877 - accuracy: 0.9295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqku6huxto__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "38913b69-e9ca-4e01-ecac-b30fe5fecde6"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9a6eed8514a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0macc\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mval_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mloss\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        }
      ]
    }
  ]
}